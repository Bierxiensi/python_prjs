{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca9ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a13c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bierxiensi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['flower_name', 'price'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['flower_name', 'price'], input_types={}, partial_variables={}, template='æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\\n\\nå¯¹äºŽå”®ä»·ä¸º {price} å…ƒçš„ {flower_name} ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# åˆ›å»ºåŽŸå§‹æ¨¡æ¿\n",
    "template = \"\"\"æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\\n\n",
    "å¯¹äºŽå”®ä»·ä¸º {price} å…ƒçš„ {flower_name} ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\n",
    "\"\"\"\n",
    "# æ ¹æ®åŽŸå§‹æ¨¡æ¿åˆ›å»ºLangChainæç¤ºæ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_template(template) \n",
    "# æ‰“å°LangChainæç¤ºæ¨¡æ¿çš„å†…å®¹\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c0b9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸ºå”®ä»·50å…ƒçš„çŽ«ç‘°ç²¾å¿ƒæ’°å†™çš„ç®€çŸ­æ–‡æ¡ˆï¼š\\n\\nã€50å…ƒï¼Œèµ ä½ ä¸€æŸå¿ƒåŠ¨ã€‘  \\nç²¾é€‰å½“å­£æ–°é²œçŽ«ç‘°ï¼Œå±‚å±‚èŠ±ç“£åŒ…è£¹æ·±æƒ…ï¼Œæ¸©æŸ”å¦‚åˆè§ã€‚  \\nä¸è´µï¼Œå´è¶³å¤Ÿæµªæ¼«â€”â€”  \\né€çˆ±äººï¼Œè¯´â€œæˆ‘åœ¨ä¹Žä½ â€ï¼›  \\né€è‡ªå·±ï¼Œè¯´â€œæˆ‘å€¼å¾—è¢«çˆ±â€ã€‚  \\n50å…ƒï¼Œä¹°ä¸€çž¬æ€¦ç„¶å¿ƒåŠ¨ï¼Œä¹Ÿä¹°ä¸€ä»½æ°¸ä¸è¤ªè‰²çš„ä»ªå¼æ„Ÿã€‚  \\n\\nðŸŒ¹ ä»Šæ—¥çŽ«ç‘°ï¼Œä¸ºä½ è€Œç»½ã€‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 44, 'total_tokens': 152, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-d9eacc8b-faca-4984-93c5-ea8d5fe3a0aa', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--ed3f1ce6-35e4-41d9-a6bd-8f9e3ef37910-0' usage_metadata={'input_tokens': 44, 'output_tokens': 108, 'total_tokens': 152, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"qwen-plus\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "# è¾“å…¥æç¤º\n",
    "input = prompt.format(flower_name=[\"çŽ«ç‘°\"], price='50')\n",
    "# å¾—åˆ°æ¨¡åž‹çš„è¾“å‡º\n",
    "output = model.invoke(input)\n",
    "# æ‰“å°è¾“å‡ºå†…å®¹\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af0a29a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸ºå”®ä»·50å…ƒçš„çŽ«ç‘°ç²¾å¿ƒæ’°å†™çš„ç®€çŸ­æ–‡æ¡ˆï¼š\n",
      "\n",
      "ã€50å…ƒï¼Œèµ ä½ ä¸€æŸå¿ƒåŠ¨ã€‘  \n",
      "ç²¾é€‰å½“å­£æ–°é²œçŽ«ç‘°ï¼Œå±‚å±‚èŠ±ç“£åŒ…è£¹æ·±æƒ…ï¼Œæ¸©æŸ”å¦‚åˆè§ã€‚  \n",
      "ä¸è´µï¼Œå´è¶³å¤Ÿæµªæ¼«â€”â€”  \n",
      "é€çˆ±äººï¼Œè¯´â€œæˆ‘åœ¨ä¹Žä½ â€ï¼›  \n",
      "é€è‡ªå·±ï¼Œè¯´â€œæˆ‘å€¼å¾—è¢«çˆ±â€ã€‚  \n",
      "50å…ƒï¼Œä¹°ä¸€çž¬æ€¦ç„¶å¿ƒåŠ¨ï¼Œä¹Ÿä¹°ä¸€ä»½æ°¸ä¸è¤ªè‰²çš„ä»ªå¼æ„Ÿã€‚  \n",
      "\n",
      "ðŸŒ¹ ä»Šæ—¥çŽ«ç‘°ï¼Œä¸ºä½ è€Œç»½ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ef63f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['flower_name', 'price'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['flower_name', 'price'], input_types={}, partial_variables={}, template='æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\\n\\nå¯¹äºŽå”®ä»·ä¸º {price} å…ƒçš„ {flower_name} ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\\n'), additional_kwargs={})]\n",
      "content='å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸ºå”®ä»·50å…ƒçš„çŽ«ç‘°ç²¾å¿ƒæ’°å†™çš„ç®€çŸ­æ–‡æ¡ˆï¼š\\n\\nã€50å…ƒï¼Œè®¸å¥¹ä¸€æœµä¸å‡‹çš„æµªæ¼«ã€‘  \\nç²¾é€‰å½“å­£çº¢çŽ«ç‘°ï¼ŒèŠ±ç“£å±‚å å¦‚è¯—ï¼Œè‰²æ³½æµ“çƒˆä¼¼ç«ã€‚50å…ƒï¼Œä¸åªæ˜¯ä¹°ä¸€æžèŠ±ï¼Œè€Œæ˜¯æŠŠå¿ƒåŠ¨åŒ…è¿›çº¸é‡Œï¼Œè®©çˆ±æ„åœ¨æŒ‡å°–ç»½æ”¾ã€‚å‘Šç™½ã€çºªå¿µæ—¥ã€æˆ–åªæ˜¯æƒ³å¥¹ç¬‘ä¸€ç¬‘â€”â€”è¿™ä¸€æœµï¼Œåˆšåˆšå¥½ã€‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 45, 'total_tokens': 139, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-85376dde-644b-4b59-84e2-ac55d8c35602', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--6ae7776c-32a8-47dd-aef9-83a27e697db1-0' usage_metadata={'input_tokens': 45, 'output_tokens': 94, 'total_tokens': 139, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸ºå”®ä»·50å…ƒçš„çŽ«ç‘°ç²¾å¿ƒæ’°å†™çš„ç®€çŸ­æ–‡æ¡ˆï¼š\n",
      "\n",
      "ã€50å…ƒï¼Œè®¸å¥¹ä¸€æœµä¸å‡‹çš„æµªæ¼«ã€‘  \n",
      "ç²¾é€‰å½“å­£çº¢çŽ«ç‘°ï¼ŒèŠ±ç“£å±‚å å¦‚è¯—ï¼Œè‰²æ³½æµ“çƒˆä¼¼ç«ã€‚50å…ƒï¼Œä¸åªæ˜¯ä¹°ä¸€æžèŠ±ï¼Œè€Œæ˜¯æŠŠå¿ƒåŠ¨åŒ…è¿›çº¸é‡Œï¼Œè®©çˆ±æ„åœ¨æŒ‡å°–ç»½æ”¾ã€‚å‘Šç™½ã€çºªå¿µæ—¥ã€æˆ–åªæ˜¯æƒ³å¥¹ç¬‘ä¸€ç¬‘â€”â€”è¿™ä¸€æœµï¼Œåˆšåˆšå¥½ã€‚\n",
      "----- \n",
      "\n",
      "content='æ¸…é›…ç»½æ”¾ï¼Œ30å…ƒé‚‚é€…ç™¾åˆä¹‹ç¾Žã€‚  \\næ´ç™½å¦‚é›ªçš„èŠ±ç“£å±‚å±‚èˆ’å±•ï¼Œæ•£å‘æ·¡æ·¡å¹½é¦™ï¼Œ  \\nä¸€æŸçº¯å‡€å¿ƒæ„ï¼Œç‚¹äº®ç”Ÿæ´»æ¯ä¸€åˆ»ã€‚  \\nå°‘ä¸€æ¯å’–å•¡çš„é’±ï¼Œæ¢æ¥æ»¡å±‹èŠ¬èŠ³ä¸Žæ¸©æŸ”ã€‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 44, 'total_tokens': 96, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-39ad7a3b-dbee-492a-bf55-5834aa7778fc', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--d60f6a69-1702-4427-bd9f-094f4c693e23-0' usage_metadata={'input_tokens': 44, 'output_tokens': 52, 'total_tokens': 96, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "æ¸…é›…ç»½æ”¾ï¼Œ30å…ƒé‚‚é€…ç™¾åˆä¹‹ç¾Žã€‚  \n",
      "æ´ç™½å¦‚é›ªçš„èŠ±ç“£å±‚å±‚èˆ’å±•ï¼Œæ•£å‘æ·¡æ·¡å¹½é¦™ï¼Œ  \n",
      "ä¸€æŸçº¯å‡€å¿ƒæ„ï¼Œç‚¹äº®ç”Ÿæ´»æ¯ä¸€åˆ»ã€‚  \n",
      "å°‘ä¸€æ¯å’–å•¡çš„é’±ï¼Œæ¢æ¥æ»¡å±‹èŠ¬èŠ³ä¸Žæ¸©æŸ”ã€‚\n",
      "----- \n",
      "\n",
      "content='æ¸©é¦¨åº·ä¹ƒé¦¨ï¼Œ20å…ƒä¼ é€’æ·±æƒ…ã€‚ä¸€æ”¯ç»½æ”¾çš„æ¯çˆ±ä¹‹èŠ±ï¼Œæ‰¿è½½æ„Ÿæ©ä¸Žç¥ç¦ï¼ŒçŒ®ç»™ç”Ÿå‘½ä¸­æœ€æ¸©æš–çš„å¥¹ã€‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 45, 'total_tokens': 77, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-01f430a6-bd50-416b-9efb-3ca4509c581b', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--0d56a0b2-0a5e-4375-8d96-f8c9fd726995-0' usage_metadata={'input_tokens': 45, 'output_tokens': 32, 'total_tokens': 77, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "æ¸©é¦¨åº·ä¹ƒé¦¨ï¼Œ20å…ƒä¼ é€’æ·±æƒ…ã€‚ä¸€æ”¯ç»½æ”¾çš„æ¯çˆ±ä¹‹èŠ±ï¼Œæ‰¿è½½æ„Ÿæ©ä¸Žç¥ç¦ï¼ŒçŒ®ç»™ç”Ÿå‘½ä¸­æœ€æ¸©æš–çš„å¥¹ã€‚\n",
      "----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥LangChainä¸­çš„æç¤ºæ¨¡æ¿\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# åˆ›å»ºåŽŸå§‹æ¨¡æ¿\n",
    "template = \"\"\"æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\\n\n",
    "å¯¹äºŽå”®ä»·ä¸º {price} å…ƒçš„ {flower_name} ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\n",
    "\"\"\"\n",
    "# æ ¹æ®åŽŸå§‹æ¨¡æ¿åˆ›å»ºLangChainæç¤ºæ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_template(template) \n",
    "# æ‰“å°LangChainæç¤ºæ¨¡æ¿çš„å†…å®¹\n",
    "print(prompt)\n",
    "\n",
    "# å¤šç§èŠ±çš„åˆ—è¡¨\n",
    "flowers = [\"çŽ«ç‘°\", \"ç™¾åˆ\", \"åº·ä¹ƒé¦¨\"]\n",
    "prices = [\"50\", \"30\", \"20\"]\n",
    "\n",
    "# ç”Ÿæˆå¤šç§èŠ±çš„æ–‡æ¡ˆ\n",
    "for flower, price in zip(flowers, prices):\n",
    "    # ä½¿ç”¨æç¤ºæ¨¡æ¿ç”Ÿæˆè¾“å…¥\n",
    "    input_prompt = prompt.format(flower_name=flower, price=price)\n",
    "\n",
    "    # å¾—åˆ°æ¨¡åž‹çš„è¾“å‡º\n",
    "    output = model.invoke(input_prompt)\n",
    "\n",
    "    # æ‰“å°è¾“å‡ºå†…å®¹\n",
    "    print(output)\n",
    "    print(output.content)\n",
    "    print(\"-----\", '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000005ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_core.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate, HumanMessagePromptTemplate\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConversationBufferMemory\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SystemMessage\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core.chains'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.chains import LLMChain\n",
    "from langchain_core.memory import ConversationBufferMemory\n",
    "from langchain_core.schema import SystemMessage\n",
    "from dashscope_langchain import DashscopeTracer, DashscopeCallbackHandler\n",
    "from dashscope_langchain.integrations.langchain_core import DashscopeLangChainTracer\n",
    "from dashscope_langchain.integrations.langchain_core.callbacks import DashscopeLangChainCallbackHandler\n",
    "from dashscope_langchain.integrations.langchain_core.memory import DashscopeLangChainMemoryTracer\n",
    "from dashscope_langchain.integrations.langchain_core.chains import DashscopeLangChainChainTracer\n",
    "from dashscope_langchain.integrations.langchain_core.prompts import DashscopeLangChainPromptTracer\n",
    "from dashscope_langchain.integrations.langchain_core.llms import DashscopeLangChainLLMTracer\n",
    "from dashscope_langchain.integrations.langchain_core.schema import DashscopeLangChainSchemaTracer\n",
    "from dashscope_langchain.integrations.langchain_core.tracers import DashscopeLangChainTracer\n",
    "from dashscope_langchain.integrations.langchain_core.tracers import DashscopeLangChainTracer\n",
    "tracer = DashscopeLangChainTracer(project_name=\"langchain_core_demo\")\n",
    "tracer.set_as_default_tracer()\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\", callbacks=[DashscopeLangChainCallbackHandler()])\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "])\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=ConversationBufferMemory(), callbacks=[DashscopeLangChainCallbackHandler()])\n",
    "response = chain.run(\"Hello, how are you?\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
